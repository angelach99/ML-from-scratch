# ML-from-scratch
Machine Learning models implementation from scratch, including Gradient descent, K-means, and GMM.

## Overview
Here I will document the various ML models I build from scratch. I also compare results using my models built from scratch with results from black-box implementation. Please click into each folder to see more.

**Gradient descent**: 
- Normal Distribution: [GD-Normal Distribution w/ fixed, exponential and inverse lr.py](https://github.com/angelach99/ML-from-scratch/blob/main/Gradient%20descent/GD-Normal%20Distribution%20w:%20fixed%2C%20exponential%20and%20inverse%20lr.py). This document involves minimizing the negative log-likelihood function with gradient descent, and minimizing functions with fixed, exponential, and inverse decay learning rate.
- Linear Regression (w/ L1 loss function): [Gurobi&L1 loss function LM.py](https://github.com/angelach99/ML-from-scratch/blob/main/Gradient%20descent/Gurobi%26L2%20loss%20function%20LM.py). This document contains a method of using Gurobi to solve a linear regression model, and a method to use make_blobs to generate nultivariate normal distributions and fit it into a Linear classifier using Gurobi.
- Logistic Regression: [LogisticR-Newton'sMethod&SGD&Mini-batch.py](https://github.com/angelach99/ML-from-scratch/blob/main/Gradient%20descent/LogisticR-Newton'sMethod%26SGD%26Mini-batch.py). This document involves training a logistic regression model using Newton's Method. 
- NLTK-Logistic Regression: [GD-nltk-text&LogisticRegression.py](https://github.com/angelach99/ML-from-scratch/blob/main/Gradient%20descent/GD-nltk-text%26LogisticRegression.py). This document contains text analytics on tweets dataset from NLTK corpus, and trained a logistic regression classifier on it.

**K-means**: [K-Means with 2 use cases.py](https://github.com/angelach99/ML-from-scratch/blob/main/K-means/K-Means%20with%202%20use%20cases.py)\
This project involves implementing K-means from scratch with 2 different use cases.

**Gaussian Mixture Model (GMM)**: [Final Project (GMM).py](https://github.com/angelach99/ML-from-scratch/blob/main/Gaussian%20Mixture%20Model/Final%20Project%20(GMM).py).\
This is the coding to implement a gaussian mixture model (GMM) from scratch with 4 different use cases.

## Acknowledgements

This project was conducted as part of the MGSC695: Optimization for Data Science, Winter 2022, with Instructor Sanjith Gopalakrishnan at Desautels Faculty of Management, McGill University.
